plot(loglam, Gcvsave, 'o', las = 1, xlab = expression(log[10](lambda)),
ylab = expression(GCV(lambda)), lwd = 2 )
# Initialize a list to store the coefficients
coeff_list <- list()
# Initialize a list to store the smoothed functional data objects
force.fd <- list()
# Loop through columns of Raw_Force
for (i in 1:ncol(Raw_Force)) {
# Remove missing values from the current column
s1 <- na.omit(Raw_Force[, i])
# Extract and normalize the time values
time <- as.numeric(time(s1))
Min <- min(time)
Max <- max(time)
# Linear time normalization function
time_norm <- function(x) {
norm_x <- matrix()
for (i in 1:length(x)) {
norm_x <- (x - Min) / (Max - Min)
return(norm_x)
}
}
# Combine time and variable into a matrix
DF <- cbind(time, s1)
# Apply linear time normalization to the time column
DF[, 1] <- time_norm(DF[, 1])
# Define the time range for the basis
TimeRng <- c(0, 1)
# Set up the B-spline basis
force_basis <- create.bspline.basis(c(0, 1), norder = 4, nbasis = 300)
# Set up the penalty object penalizing the 2nd derivative and initially set lambda = 0.0001
force_fdPar = fdPar(fdobj = force_basis, Lfdobj = 2, lambda = 0.0001)
# Smooth the data using the penalty object
force.pen.smooth = smooth.basis(argvals = DF[, 1], y = DF[, 2], fdParobj = force_fdPar)
# Create a new data frame for the coefficients and assign the values
coeff_df <- data.frame(t(force.pen.smooth$fd[["coefs"]]))
# Store the smoothed functional data object in the force.fd list
force.fd[[i]] <- force.pen.smooth$fd
# Add the data frame to the coeff_list
coeff_list[[i]] <- coeff_df
par(mfrow=c(2,2))
# Plot the smooth curve
plot(DF[, 1], DF[, 2], type = 'p', lwd = 0.00005, xlab = 'Time', ylab = 'Force',
main = paste0(colnames(Raw_Force[i])))
lines(force.pen.smooth$fd, col = 'red')
}
Raw_F<-read.csv("Raw_Force.csv")
Raw_F$SN<-c(1:553)
# Reshape the data
Raw_F_long <- Raw_F%>%
pivot_longer(cols = -SN, names_to = "Column", values_to = "Value")
# Plot the data
ggplot(Raw_F_long, aes(x = SN, y = Value, color = Column)) +
geom_line() +
ggtitle("Force Profiles") +
xlab("Time") +
ylab("Force") +
theme_minimal()
# Define the order of the B-spline basis
norder <- 4
# Remove missing values from the s0103 column in the Raw_Force dataframe and extract time
s1 <- na.omit(Raw_Force$s0103)
time <- time(s1)
# Calculate the minimum and maximum values of the time vector
Min <- min(time)
Max <- max(time)
# Linear time normalization function
time_norm <- function(x) {
norm_x <- matrix()
for (i in 1:length(x)) {
# Apply linear time normalization
norm_x <- (x - Min) / (Max - Min)
return(norm_x)
}
}
# Form the matrix of time and Variable
DF <- cbind(time, s1)
# Apply linear time normalization to the time column
DF[, 1] <- time_norm(DF[, 1])
# Create a B-spline basis with specific parameters
force_basis <- create.bspline.basis(c(0, 1), norder = norder, nbasis = 300)
# Define a sequence of lambda values for the GCV search
loglam <- seq(-6, 0, 0.25)
# Initialize vectors to store GCV and degrees of freedom (DF) values
Gcvsave <- rep(NA, length(loglam))
names(Gcvsave) <- loglam
Dfsave <- Gcvsave
# Loop through different lambda values and calculate GCV and DF
for (i in 1:length(loglam)) {
# Define a new penalty based on the current lambda value
hgtfdPari <- fdPar(force_basis, 2, 10^loglam[i])
# Smooth the data with the updated penalty
hgtSm.i <- smooth.basis(DF[, 1], DF[, 2], hgtfdPari)
# Store GCV and DF values
Gcvsave[i] <- sum(hgtSm.i$gcv)
Dfsave[i] <- hgtSm.i$df
}
# Plot GCV values against the logarithm of lambda
plot(loglam, Gcvsave, 'o', las = 1, xlab = expression(log[10](lambda)),
ylab = expression(GCV(lambda)), lwd = 2 )
cum.propvar<-cumsum(force.pcalist$varprop)
# Initialize a list to store the coefficients
coeff_list <- list()
# Initialize a list to store the smoothed functional data objects
force.fd <- list()
# Loop through columns of Raw_Force
for (i in 1:ncol(Raw_Force)) {
# Remove missing values from the current column
s1 <- na.omit(Raw_Force[, i])
# Extract and normalize the time values
time <- as.numeric(time(s1))
Min <- min(time)
Max <- max(time)
# Linear time normalization function
time_norm <- function(x) {
norm_x <- matrix()
for (i in 1:length(x)) {
norm_x <- (x - Min) / (Max - Min)
return(norm_x)
}
}
# Combine time and variable into a matrix
DF <- cbind(time, s1)
# Apply linear time normalization to the time column
DF[, 1] <- time_norm(DF[, 1])
# Define the time range for the basis
TimeRng <- c(0, 1)
# Set up the B-spline basis
force_basis <- create.bspline.basis(c(0, 1), norder = 4, nbasis = 300)
# Set up the penalty object penalizing the 2nd derivative and initially set lambda = 0.0001
force_fdPar = fdPar(fdobj = force_basis, Lfdobj = 2, lambda = 0.0001)
# Smooth the data using the penalty object
force.pen.smooth = smooth.basis(argvals = DF[, 1], y = DF[, 2], fdParobj = force_fdPar)
# Create a new data frame for the coefficients and assign the values
coeff_df <- data.frame(t(force.pen.smooth$fd[["coefs"]]))
# Store the smoothed functional data object in the force.fd list
force.fd[[i]] <- force.pen.smooth$fd
# Add the data frame to the coeff_list
coeff_list[[i]] <- coeff_df
# Plot the smooth curve
plot(DF[, 1], DF[, 2], type = 'p', lwd = 0.00005, xlab = 'Time', ylab = 'Force',
main = paste0(colnames(Raw_Force[i])))
lines(force.pen.smooth$fd, col = 'red')
}
# Creating an empty matrix to store the fd coefficients
coefs <- matrix(data = NA, nrow = 300, ncol = 34)
# Loop through each element in the force.fd list
for (i in 1:length(force.fd)) {
# Extract and store the coefficients in the 'coefs' matrix
coefs[, i] <- force.fd[[i]][["coefs"]]
}
# Set row names of 'coefs' matrix to match those of the first set of coefficients
row.names(coefs) <- row.names(force.fd[[1]][["coefs"]])
# Set column names of 'coefs' matrix to match the column names of Raw_Force
colnames(coefs) <- colnames(Raw_Force)
# Create vectors for time, repetitions, and values
time <- c(1:300)
reps <- colnames(Raw_Force)
values <- c('value')
# Create a list for fdnames
fdname <- list('time' = time, 'reps' = reps, 'values' = values)
# Create a functional data object (FD) using the coefficients, basis, and fdnames
Force_fd <- fd(coefs, force_basis, fdnames = fdname)
# Check the class of the resulting FD
class(Force_fd)
# Plot the smooth curves using the created FD
plot(Force_fd, xlab = 'time', ylab = 'force', main = 'Smooth curves')
force.pcalist = pca.fd(Force_fd,4,harmfdPar=fdPar(Force_fd))
plot(force.pcalist)
cum.propvar<-cumsum(force.pcalist$varprop)
data.frame(1:4,cum.propvar)
require(GGally)
require(e1071)
require(ggpubr)
require(cowplot)
library(fdacluster)
library(funHDDC)
## Create an empty matrix 'time_mat' to store time values
time_mat <- matrix(data = NA, nrow = 34, ncol = 300)
# Set row names of 'time_mat' to match column names of 'Raw_Force'
row.names(time_mat) <- colnames(Raw_Force)
# Populate 'time_mat' with values from 1 to 300 for each row
for (i in 1:nrow(time_mat)) {
time_mat[i,] <- rbind(c(1:300))
}
# Define a function 'time_norm2' for time normalization
time_norm2 <- function(x) {
# Create an empty matrix 'Norm_tr' to store normalized values
Norm_tr <- matrix(data = NA, nrow = 34, ncol = 300)
# Set row names of 'Norm_tr' to match column names of 'Raw_Force'
row.names(Norm_tr) <- colnames(Raw_Force)
# Normalize each row of 'x' and store the results in 'Norm_tr'
for (i in 1:nrow(x)) {
Norm_tr[i,] <- (x[i,] - min(x[i,])) / (max(x[i,]) - min(x[i,]))
}
return(Norm_tr)
}
# Apply the 'time_norm2' function to normalize 'time_mat' and store the result in 'T_R'
T_R <- time_norm2(time_mat)
## Create an empty matrix 'time_mat' to store time values
time_mat <- matrix(data = NA, nrow = 34, ncol = 300)
# Set row names of 'time_mat' to match column names of 'Raw_Force'
row.names(time_mat) <- colnames(Raw_Force)
# Populate 'time_mat' with values from 1 to 300 for each row
for (i in 1:nrow(time_mat)) {
time_mat[i,] <- rbind(c(1:300))
}
# Define a function 'time_norm2' for time normalization
time_norm2 <- function(x) {
# Create an empty matrix 'Norm_tr' to store normalized values
Norm_tr <- matrix(data = NA, nrow = 34, ncol = 300)
# Set row names of 'Norm_tr' to match column names of 'Raw_Force'
row.names(Norm_tr) <- colnames(Raw_Force)
# Normalize each row of 'x' and store the results in 'Norm_tr'
for (i in 1:nrow(x)) {
Norm_tr[i,] <- (x[i,] - min(x[i,])) / (max(x[i,]) - min(x[i,]))
}
return(Norm_tr)
}
# Apply the 'time_norm2' function to normalize 'time_mat' and store the result in 'T_R'
T_R <- time_norm2(time_mat)
## Create an empty matrix 'time_mat' to store time values
time_mat <- matrix(data = NA, nrow = 34, ncol = 300)
# Set row names of 'time_mat' to match column names of 'Raw_Force'
row.names(time_mat) <- colnames(Raw_Force)
# Populate 'time_mat' with values from 1 to 300 for each row
for (i in 1:nrow(time_mat)) {
time_mat[i,] <- rbind(c(1:300))
}
# Define a function 'time_norm2' for time normalization
time_norm2 <- function(x) {
# Create an empty matrix 'Norm_tr' to store normalized values
Norm_tr <- matrix(data = NA, nrow = 34, ncol = 300)
# Set row names of 'Norm_tr' to match column names of 'Raw_Force'
row.names(Norm_tr) <- colnames(Raw_Force)
# Normalize each row of 'x' and store the results in 'Norm_tr'
for (i in 1:nrow(x)) {
Norm_tr[i,] <- (x[i,] - min(x[i,])) / (max(x[i,]) - min(x[i,]))
}
return(Norm_tr)
}
# Apply the 'time_norm2' function to normalize 'time_mat' and store the result in 'T_R'
T_R <- time_norm2(time_mat)
caps<-compare_caps(x=T_R,y=Force_fd,n_clusters=1:6, clustering_method="kmeans", warping_class ="none",centroid_type = "mean",cluster_on_phase = FALSE)
plot(
caps,
validation_criterion = c("wss", "silhouette"),
what = c("mean", "distribution"),
)
# Perform Functional Data Analysis K-Means clustering
# - 'x' represents the data for time normalization
# - 'y' represents the smoothed force curves
# - 'n_clusters' specifies the number of clusters (2 in this case)
# - 'warping_class' defines the warping class (in this case, "none" for no warping)
# - 'cluster_on_phase' determines whether clustering is based on phase (set to FALSE)
# - 'use_verbose' controls verbose output (set to FALSE for no verbosity)
N.Kmeans.amp_cluster2 <- fdakmeans(
x = T_R,
y = Force_fd,
n_clusters = 2,
warping_class = "none",
cluster_on_phase = FALSE,
use_verbose = FALSE
)
# Plot the amplitude-based clusters obtained from FDA K-Means
plot(N.Kmeans.amp_cluster2, type = 'amplitude')
# Extract the scores from the 'force.pcalist' object
scores <- force.pcalist$scores
# Rename the columns of the 'scores' matrix
colnames(scores) <- c("pc1", "pc2", "pc3", "pc4")
# Set row names of the 'scores' matrix to match column names of 'Raw_Force'
row.names(scores) <- colnames(Raw_Force)
# Calculate the correlation matrix of the scores
correlation_matrix <- cor(scores)
# Create an empty numeric vector to store the within-group sum of squares (WGSS)
WGSS <- vector(mode = "numeric")
# Get the number of rows (data points) in the 'scores' dataset
n <- nrow(scores)
# Calculate the WGSS for k = 1 (initial value)
WGSS[1] <- (n - 1) * sum(apply(scores, 2, var))
# Loop through different values of k from 2 to 10
for (k in 2:10) {
# Calculate the WGSS for the current value of k using k-means clustering
# and store it in the 'WGSS' vector
WGSS[k] <- sum(kmeans(scores, centers = k, nstart = 20)$withinss)
}
# Create a ggplot object to visualize the WGSS values
ggplot(data = as.data.frame(WGSS), aes(x = 1:10, y = WGSS)) +
xlab("k") +
ylab("Within-group sum of squares") +
theme_bw() +
geom_line() +
geom_point()
# Set a random seed for reproducibility
set.seed(4)
# Perform k-means clustering with 2 centers on the 'FPC scores'
K_cl2 <- kmeans(scores, centers = 2, nstart = 20)
# Plot the smoothed force curves (Force_fd) with colors based on the cluster assignments
plot(Force_fd, col = K_cl2$cluster)
tab<-table(K_cl2$cluster,N.Kmeans.amp_cluster2$memberships)
classAgreement(tab)
# Extract columns from the 'coefs' matrix where cluster membership is 1
group_1 <- coefs[, which(N.Kmeans.amp_cluster2$memberships == 1)]
# Define the time vector
time <- 1:300
# Get the column names (reps) of the 'group_1' matrix
reps <- colnames(group_1)
# Create a list for specifying the functional data object names (fdnames)
fdname <- list('time' = time, 'reps' = reps, 'values' = 'value')
# Create the functional data object for 'group_1'
group1.fd <- fd(group_1, force_basis, fdnames = fdname)
# Extract columns from the 'coefs' matrix where cluster membership is 2
group_2 <- coefs[, which(N.Kmeans.amp_cluster2$memberships == 2)]
# Define the time vector
time <- 1:300
# Get the column names (reps) of the 'group_2' matrix
reps <- colnames(group_2)
# Create a list for specifying the functional data object names (fdnames)
fdname <- list('time' = time, 'reps' = reps, 'values' = 'value')
# Create the functional data object for 'group_2' and store it as 'group2.fd'
group2.fd <- fd(group_2, force_basis, fdnames = fdname)
# Create a data frame 'Force.mean.dat' with columns 'x', 'mean.group1', and 'mean.group2'
Force.mean.dat <- data.frame(
x = seq(0, 1, length = 300),
mean.group1 = eval.fd(seq(0, 1, length = 300), mean.fd(group1.fd)),
mean.group2 = eval.fd(seq(0, 1, length = 300), mean.fd(group2.fd))
)
# Rename the columns of 'Force.mean.dat'
names(Force.mean.dat) <- c("x", "group_1", "group_2")
# Create a ggplot to visualize the mean force curves for both groups
ggplot(data = Force.mean.dat, aes(x = x, y = group_1)) +
geom_line(colour = "#009E73") +  # Line for 'group_1' with green color
geom_line(aes(x = x, y = group_2), colour = "#CC79A7") +  # Line for 'group_2' with pink color
xlab("Time") +
ylab("Mean Force") +
theme_bw()
tres = tperm.fd(group1.fd,group2.fd, nperm = 200, q = 0.05)
?fdakmeans
# Fit a linear regression model with a logarithmic transformation of 'Annual_Earnings'
model2.wage <- lm(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages)
# Display a summary of the regression model
summary(model2.wage)
#reduced model
model_reduced<-lm(Annual_Earnings~No_Of_Weeks+WeeklyHours+Time_paid_employ,data = wages)
#full Models
#Gender
model_full1<-lm(log(Annual_Earnings)~No_Of_Weeks+Gender.f+WeeklyHours+Time_paid_employ,data=wages)
View(wages)
#reduced model
model_reduced<-lm(Annual_Earnings~No_Of_Weeks+WeeklyHours+Time_paid_employ,data = wages)
#full Models
#Gender
model_full1<-lm(log(Annual_Earnings)~No_Of_Weeks+Gender+WeeklyHours+Time_paid_employ,data=wages)
#sector
model_full2<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+Sector+Time_paid_employ,data=wages)
#Job category
model_full3<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+JobCategory+Time_paid_employ,data=wages)
#service
model_full4<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+service+Time_paid_employ,data=wages)
# Partial F.tests
anova(model_reduced,model_full1)
anova(model_reduced,model_full2)
anova(model_reduced,model_full3)
anova(model_reduced,model_full4)
#reduced model
model_reduced<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+Time_paid_employ,data = wages)
#full Models
#Gender
model_full1<-lm(log(Annual_Earnings)~No_Of_Weeks+Gender+WeeklyHours+Time_paid_employ,data=wages)
#sector
model_full2<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+Sector+Time_paid_employ,data=wages)
#Job category
model_full3<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+JobCategory+Time_paid_employ,data=wages)
#service
model_full4<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+service+Time_paid_employ,data=wages)
# Partial F.tests
anova(model_reduced,model_full1)
anova(model_reduced,model_full2)
anova(model_reduced,model_full3)
anova(model_reduced,model_full4)
#reduced model
model_reduced<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+Time_paid_employ,data = wages)
#full Models
#Gender
model_full1<-lm(log(Annual_Earnings)~No_Of_Weeks+Gender+WeeklyHours+Time_paid_employ,data=wages)
#sector
model_full2<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+Sector+Time_paid_employ,data=wages)
#Job category
model_full3<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+JobCategory+Time_paid_employ,data=wages)
#service
model_full4<-lm(log(Annual_Earnings)~No_Of_Weeks+WeeklyHours+service+Time_paid_employ,data=wages)
# Partial F.tests
anova(model_reduced,model_full1)
anova(model_reduced,model_full2)
anova(model_reduced,model_full3)
anova(model_reduced,model_full4)
Anova(model2.wage,type='III')
# Reduced Model
model_reduced <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + Time_paid_employ, data = wages)
# Full Models
# Gender
model_full1 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + Gender + WeeklyHours + Time_paid_employ, data = wages)
# Sector
model_full2 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + Sector + Time_paid_employ, data = wages)
# Job Category
model_full3 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + JobCategory + Time_paid_employ, data = wages)
# Service
model_full4 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + service + Time_paid_employ, data = wages)
# Partial F-Tests
# Compare the reduced model to each full model using the ANOVA (Analysis of Variance) test.
# Gender
anova_gender <- anova(model_reduced, model_full1)
# Sector
anova_sector <- anova(model_reduced, model_full2)
# Job Category
anova_job_category <- anova(model_reduced, model_full3)
# Service
anova_service <- anova(model_reduced, model_full4)
# Reduced Model
model_reduced <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + Time_paid_employ, data = wages)
# Full Models
# Gender
model_full1 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + Gender + WeeklyHours + Time_paid_employ, data = wages)
# Sector
model_full2 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + Sector + Time_paid_employ, data = wages)
# Job Category
model_full3 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + JobCategory + Time_paid_employ, data = wages)
# Service
model_full4 <- lm(log(Annual_Earnings) ~ No_Of_Weeks + WeeklyHours + service + Time_paid_employ, data = wages)
# Partial F-Tests
# Compare the reduced model to each full model using the ANOVA (Analysis of Variance) test.
# Gender
anova_gender <- anova(model_reduced, model_full1)
# Sector
anova_sector <- anova(model_reduced, model_full2)
# Job Category
anova_job_category <- anova(model_reduced, model_full3)
# Service
anova_service <- anova(model_reduced, model_full4)
# Display the ANOVA results for Gender
print(anova_gender)
# Display the ANOVA results for Sector
print(anova_sector)
# Display the ANOVA results for Job Category
print(anova_job_category)
# Display the ANOVA results for Service
print(anova_service)
# Fit a linear regression model with a logarithmic transformation of 'Annual_Earnings'
wage_model <- lm(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages)
# Display a summary of the regression model
summary(wage_model)
#Diagnostic plots
# Compute the residuals of the transformed Annual Earnings prediction model
model.res <- rstandard(wage_model)
# Create a histogram to visualize the distribution of residuals
hist(wage_model)
# Fit a linear regression model with a logarithmic transformation of 'Annual_Earnings'
wage_model <- lm(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages)
# Display a summary of the regression model
summary(wage_model)
#Diagnostic plots
# Compute the residuals of the transformed Annual Earnings prediction model
wage_model.res <- rstandard(wage_model)
# Create a histogram to visualize the distribution of residuals
hist(wage_model.res)
# Create a plot to visualize the 'model_.age' predictions
plot(wage_model)
wage_model$coefficients
round(exp(wage_model$coefficients),3)
round((exp(wage_model$coefficients)-1)*100,3)
round((exp(wage_model$coefficients)),3)
round((exp(wage_model$coefficients)-1)*100,3)
# Define training control
set.seed(123)
train.control <- trainControl(method = "repeatedcv", number = 10,repeats=3)
model_val<- trainlog(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,method = "lm",
trControl = train.control)
# Define training control
set.seed(123)
train.control <- trainControl(method = "repeatedcv", number = 10,repeats=3)
model_val<- train(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,method = "lm",
trControl = train.control)
# Summarize the results
print(model_val)
# Set the seed for reproducibility
set.seed(123)
# Define the training control parameters
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
# Train a linear regression model using the specified predictors
model_val <- train(
log(Annual_Earnings) ~ No_Of_Weeks + Gender + Time_paid_employ + WeeklyHours + service + JobCategory + Sector,
data = wages,
method = "lm",
trControl = train.control
)
# Print and summarize the results of the model validation
print(model_val)
library(robustbase)
robust_model<-lmrob(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,control=lmrob.control(max.it=100))
summary(robust_model)
library(robustbase)
robust_model<-lmrob(Annual_Earnings ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,control=lmrob.control(max.it=100))
summary(robust_model)
library(robustbase)
robust_model<-lmrob(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,control=lmrob.control(max.it=100))
summary(robust_model)
library(robustbase)
robust_model<-lmrob(Annual_Earnings ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,control=lmrob.control(max.it=100))
summary(robust_model)
library(robustbase)
robust_model<-lmrob(log(Annual_Earnings) ~ No_Of_Weeks+Gender+Time_paid_employ+WeeklyHours+service+JobCategory+Sector, data = wages,control=lmrob.control(max.it=100))
summary(robust_model)
